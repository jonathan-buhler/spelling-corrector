{
 "cells": [
  {
   "source": [
    "# Building a Spelling Corrector\n",
    "\n",
    "Automatic spelling correction is something we encournter every day. But how it works isn't immediately obvious. With this notebook I aim to show how to build an understandable spelling corrector that, as a bonus, also works reasonably well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "married-chassis",
   "metadata": {},
   "source": [
    "## First, some probability theory\n",
    "### Equation to maximize\n",
    "Given a misspelled word `w`, we want to create a function `correct(w)` which returns the word the user was most likely trying to type. As there is unavoidable ambiguity in correcting a word (\"ther\" could be \"their\", \"there\", or \"the\", just to name a few) we will assign probabilities to each possible correction (candidate). Each candidate `c`'s probability represents the likelihood that given misspelled word `w`, `c` is the intended word: `P(c|w)`.\n",
    "\n",
    "[Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes'_theorem) tells us that `P(c|w)` is equivalent to `(P(c) * P(w|c)) / (P(w)`. `P(w)` is the same for all `c` so we can ignore it. This leaves us with the equation: `P(c) * P(w|c)` to maximize over all candidates `c` for a misspelled word `w`.\n",
    "\n",
    "### Breaking down the equation\n",
    "`P(c)`: The probability of the candidate word occuring in an English text. Words like \"the\", \"and\" etc. occur far more frequently than words like \"monopoly\" or \"horticulture\". This gives them a higher probabilty of occuring.\n",
    "\n",
    "`P(w|c)`: The probability that the misspelled word `w` was typed when the author meant `c`. For example, `P(\"clasroom\"|\"classroom\")` is very high, while `P(\"cladfalsasrosfsafam\"|\"classroom\")` is very low.\n",
    "\n",
    "Over all candidates `c`: We can't evaluate the equation for every word in the English language, so instead we'll evaluate it on words that are a couple simple edits away from the misspelled word `w`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-combination",
   "metadata": {},
   "source": [
    "## Candidate selection\n",
    "We define a simple edit to a word as any of the following:\n",
    "- Deletion: Remove one letter\n",
    "- Swap: Swap two adjacent letters\n",
    "- Substitution: Change one letter to another\n",
    "- Insertion: Add a new letter\n",
    "\n",
    "This is implemented by the function `one_edit_from`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "several-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS = \"abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_edit_from(word):\n",
    "    # Generates splits of a word ex. \"dog\" -> (\"\", \"dog\"), (\"d\", \"og\"), (\"do\", \"g\"), (\"dog\", \"\")\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "\n",
    "    deletes = [l + r[1:] for (l, r) in splits if r]\n",
    "    swaps = [l + r[1] + r[0] + r[2:] for (l, r) in splits if len(r) > 1]\n",
    "    substitutes = [l + x + r[1:] for (l, r) in splits for x in LETTERS]\n",
    "    inserts = [l + x + r for (l, r) in splits for x in LETTERS]\n",
    "\n",
    "    return set(deletes + swaps + substitutes + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atomic-porcelain",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(one_edit_from(\"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjacent-laugh",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fog', 'dvg', 'dogn', 'dotg', 'qog', 'zdog', 'dogz', 'edog']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "list(one_edit_from(\"dog\"))[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-calgary",
   "metadata": {},
   "source": [
    "This list can get very long for longer words. We can handle this by filtering out words that don't exist in the English language. To do this, we create a constant `WORDS` stores a list of all the words in an English dictionary (read in from a text file). The `utils` functions are included at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changing-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_words\n",
    "WORDS = get_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efficient-registration",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['deaths',\n",
       " 'dissociate',\n",
       " 'occupancy',\n",
       " 'cripple',\n",
       " 'punishments',\n",
       " 'airliner',\n",
       " 'romantics',\n",
       " 'thousandths']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "list(WORDS)[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-recovery",
   "metadata": {},
   "source": [
    "We can now make the function `filter_unknown` which removes all words not in `WORDS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unknown(words):\n",
    "    return set(word for word in words if word in WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diagnostic-rebel",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bog',\n",
       " 'cog',\n",
       " 'dag',\n",
       " 'dig',\n",
       " 'do',\n",
       " 'dob',\n",
       " 'doc',\n",
       " 'doe',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'doh',\n",
       " 'don',\n",
       " 'dos',\n",
       " 'dot',\n",
       " 'dug',\n",
       " 'fog',\n",
       " 'hog',\n",
       " 'jog',\n",
       " 'log',\n",
       " 'tog',\n",
       " 'wog'}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "filter_unknown(one_edit_from(\"dog\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-digest",
   "metadata": {},
   "source": [
    "This is a far more manageable list, and is more useful as well because we don't want to correct misspelled words into words that don't exist in the English language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-asset",
   "metadata": {},
   "source": [
    "To expand our search-space, we'll also include candidates that are two simple edits from the original word. This function, `two_edits_from` just stacks calls to `one_edit_from`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dress-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_edits_from(word):\n",
    "    return set(\n",
    "        second_edit\n",
    "        for edit in one_edit_from(word)\n",
    "        for second_edit in one_edit_from(edit)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pharmaceutical-kruger",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fog', 'fob', 'hug', 'how', 'logo', 'nag', 'dry', 'yo']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "list(filter_unknown(two_edits_from(\"dog\")))[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "imported-divorce",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ample', 'examine', 'example', 'examples', 'sample', 'trample'}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "filter_unknown(two_edits_from(\"example\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-bikini",
   "metadata": {},
   "source": [
    "Tying it all together, we write the function `get_candidates` which accepts a word `w` and returns `w` if `w` is known, else all known words one edit from `w`. If there are no known words one edit from `w` then it returns all known words two edits from `w`. Failing that, it just returns `w`. This function is meant to represent `P(w|c)` as it returns the candidates most likely to be the intended word. However, it falsely assumes that any candidate one edit away from the original word is more likely to be intended than a word two edits away. This isn't always true. For example, if `w` is \"rember\" then our model thinks \"member\" is infinitely more likely than \"remember\" which is clearly not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "devoted-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(word):\n",
    "    if word in WORDS:\n",
    "        return [word]\n",
    "    \n",
    "    return (\n",
    "        filter_unknown(one_edit_from(word))\n",
    "        or filter_unknown(two_edits_from(word))\n",
    "        or [word]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-reading",
   "metadata": {},
   "source": [
    "## Evaluating P(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-release",
   "metadata": {},
   "source": [
    "To calculate the `p(c)` for any word `c`, we will use a large corpus of text and count the occurences of `c` within the text and divide it by the total amount of words in the corpus. This will give us a good, if a bit crude, estimate of the probability of `c` showing up in our text. Our corpus will be a text file containing a large sample of ebooks from Project Gutenberg. We create a Counter that reads in all the words accumulates counts for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tropical-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_word_counts\n",
    "WORD_COUNTS = get_word_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "convenient-sullivan",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "80030"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "WORD_COUNTS[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stainless-stocks",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "WORD_COUNTS[\"monopoly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "happy-kuwait",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "WORD_COUNTS[\"horticulture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spatial-simple",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the', 80030),\n",
       " ('of', 40025),\n",
       " ('and', 38313),\n",
       " ('to', 28766),\n",
       " ('in', 22050),\n",
       " ('a', 21153),\n",
       " ('that', 12512),\n",
       " ('he', 12401)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "WORD_COUNTS.most_common(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-surgery",
   "metadata": {},
   "source": [
    "We can now create the function `probability_of` which returns our estimation of `p(c)` given candidate word `c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "boxed-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of(word):\n",
    "    return WORD_COUNTS[word] / sum(WORD_COUNTS.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "casual-attraction",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.07177378924890877"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "probability_of(\"the\") # Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "psychological-keyboard",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.3452540781377379e-05"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "probability_of(\"monopoly\") # Not large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-assistant",
   "metadata": {},
   "source": [
    "## Putting it together\n",
    "We can now generate candidates and evaluate their probability of occuring. From these ingredients we can define a simple function to return the candidate with the maximum probability, completing our spelling corrector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "different-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    return max(get_candidates(word), key=probability_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indie-postcard",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "speling -> spelling\n",
      "computinga -> computing\n",
      "clasrom -> classroom\n",
      "jonahtan -> jonahtan\n",
      "ptyhon -> python\n",
      "prgrammin -> programming\n"
     ]
    }
   ],
   "source": [
    "misspellings = [\"speling\", \"computinga\", \"clasrom\", \"ptyhon\", \"prgrammin\", \"jonahtan\"]\n",
    "for misspelling in misspellings:\n",
    "    print(f\"{misspelling} -> {correct(misspelling)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-jones",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}